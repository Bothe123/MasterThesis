\chapter{Methodology}

\section{Method for calculating the MSD} 

For the calculation of the \gls{msd} we concentrate on the one-dimensional case, as this simplifies the calculations and the generalization to higher dimensions is clear, because the \gls{PDF} of the process (\ref{eqn:defPsiXT}) is isotropic and the normalization takes care of the angular integral. 

The one-dimensional \gls{msd} $\mean{x^2}(t)$ is defined via the integral 
%
\begin{align}
\mean{x^2}(t) = \int_{\mathbb{R}} x^2 \gls{psi}(x,t) dx ,
\end{align}
%
which is closely related to the Fourier Laplace transform of the \gls{PDF} for the process, as we can see when we expand it for small $k$:
%
\begin{align}
\gls{pdf}(k|s) &= \int_{\mathbb{R}}  e^{ik x} p(x|s) dx  \\
&= \int_{\mathbb{R}}   p(x|s) dx +  i k \int_{\mathbb{R}}   x p(x|s) dx - \frac{k^2}{2} \int_{\mathbb{R}}   x^2 p(x|s) dx \\
&= 1 - \frac{k^2}{2} \mean{x^2}(s)  + ... \quad ,
\end{align}
%
where we used that the \gls{PDF} is normalized to one and that the first moment of an isotropic process vanishes. This implies 
%
\begin{align}
\mean{x^2}(s) = - \left[ \npder{}{k}{2} \gls{pdf}(k|s) \right]_{k=0} \label{eqn:MSDDerivative}, 
\end{align}
%
which allows us to calculate the \gls{msd} directly without knowledge of the full \gls{PDF}.

For the ordinary or non-aged case we can use Eq. (\ref{eqn:pdfFourierLaplaceI}) for the \gls{PDF} in the Fourier Laplace domain:
%
\begin{align}
\gls{pdf}(k|s) = \gls{comp}(k,s) \gls{rest}(k|s) \label{eqn:PDFFourierLaplaceMethods} .
\end{align}
%
We can expand $\gls{comp}$ and $\gls{rest}$ similarly to what we did for the \gls{PDF} resulting in in 
%
\begin{align}
\gls{rest}(k|s) &= \gls{rest}_0(s) - \frac{1}{2} k^2 \gls{rest}_2(s) + o(k^2) \label{eqn:rExpansion}\\
\gls{comp}(k,s) &= \gls{comp}_0(s)- \frac{1}{2} k^2 \gls{comp}_2(s) + o(k^2) .
\end{align}
%
Here the first moments vanish again and we introduced the following notation for the marginal moments:
%
\begin{align}
\gls{rest}_0(s) &=   \gls{rest}(k=0|s), \qquad \gls{rest}_2 (s) =   \left[ \npder{}{k}{2} \gls{rest}(k|s) \right]_{k=0}, \\
\gls{comp}_0(s) &=   \gls{comp}(k=0|s), \qquad \gls{comp}_2 (s) =   \left[ \npder{}{k}{2} \gls{comp}(k|s) \right]_{k=0}.
\end{align}
%
Inserting these expansions into Eq. (\ref{eqn:PDFFourierLaplaceMethods}) we find for the \gls{PDF}
%
\begin{align}
\gls{pdf}(k|s)  = \gls{comp}_0(s)\gls{rest}_0(s) - \frac{k^2}{2}\left[\gls{comp}_0(s) \gls{rest}_2(s)+\gls{comp}_2(s)\gls{rest}_0(s)\right] +o(k^2) ,
\end{align}
%
from which it follows by Eq. (\ref{eqn:MSDDerivative}) that in the ordinary case the \gls{msd} is given by 
%
\begin{align}
\mean{x^2}(s) = \gls{comp}_0(s) \gls{rest}_2(s)+\gls{comp}_2(s)\gls{rest}_0(s) \label{eqn:x2Ordinary}. 
\end{align}

For the aged case we start from the result found in (\ref{eqn:pdfAgedFourierLaplace}),
%
\begin{align}
\gls{pdf}(k|s,t_a) =  \gls{first}(k,s|t_a)  \gls{comp}(k,s) \gls{rest}(k|s) + \gls{single}(k|s,t_a) ,
\end{align}
%
and use similar expansions for the transforms of the single step density and the first step density:
%
\begin{align}
\gls{single}(k|s,t_a) &= \gls{single}_0(s,t_a) - \frac{1}{2} k^2 \gls{single}_2 (s,t_a) + o(k^2)\\ 
\gls{first}(k,s|t_a) &= \gls{first}_0(s|t_a)- \frac{1}{2} k^2 \gls{first}_2(s|t_a) + o(k^2) .
\end{align}
%
Thus we find for the \gls{PDF}
%
\begin{align}
\begin{split}
 p(k|s) = \gls{first}_0(s|t_a)\gls{comp}_0(s)\gls{rest}_0(s) - \frac{k^2}{2} &\left[ \gls{first}_0(s|t_a)\gls{comp}_0(s) \gls{rest}_2(s) +\gls{first}_0(s|t_a)\gls{comp}_2(s)\gls{rest}_0(s)  \right. \\
 & \quad \left. + \gls{first}_2(s|t_a)\gls{comp}_0(s) \gls{rest}_0(s) + \gls{single}_2(s,t_a)\right] +o(k^2) .
\end{split}
\end{align}
%
Again using Eq. (\ref{eqn:MSDDerivative}) we obtain for the \gls{msd} in the aged case:
%
\begin{align}
\mean{x^2}(s) =& \gls{first}_0(s|t_a)\gls{comp}_0(s) \gls{rest}_2(s) +\gls{first}_0(s|t_a)\gls{comp}_2(s)\gls{rest}_0(s)  \\
& + \gls{first}_2(s|t_a)\gls{comp}_0(s) \gls{rest}_0(s) + \gls{single}_2(s,t_a)  \nonumber \label{eqn:x2Aged}.
\end{align}

To extract the asymptotic results from Eqs. (\ref{eqn:x2Ordinary}) (\ref{eqn:x2Aged}) we need to look at the $t \to \infty$ limit, which corresponds to the $s \to 0$ limit in the Laplace domain. \\
The general strategy is therefore to find expressions for the quantities $\gls{comp}_0, \gls{first}_0, \gls{rest}_0, \gls{comp}_2, \gls{first}_2, \gls{rest}_2$ in the Laplace domain to leading order in $s$. They are then inserted into the respective equations for the \gls{msd}, which is then transformed back into the time domain. $\gls{single}_2$ can be calculated directly in the time domain as it is not part of a product in expression for the aged \gls{msd}. 

The key tool for moving between the Laplace and the time domain is the Tauberian theorem. It states that the Laplace transform of a function $f(t)$ following a power law for large $t$ through the formula \cite{firstSteps}
\todo{first hand source}
% 
{\color{red}
\begin{equation}
 f(t) \simeq t^{\rho-1} L(t) \;\; \leftrightarrow \;\; f(s) \simeq \Gamma(\rho) s^{-\rho} L\left(\frac{1}{s}\right) \label{eqn:tauberian} ,
\end{equation}
}
%
if $\rho \geq 0 $ and $L(t)$ is slowly varying, i.e. when
%
\begin{align}
\lim_{t \to \infty} \frac{L(C \; t)}{L(t)} = 1 .
\end{align}
%
For general $\rho$ the slightly more complicated formula 
%
\begin{align}
 f(s) = \sum_{k=0}^{k_{\max}} \frac{(-1)^k}{k!} I^{f}_k s^k + L \Gamma(\rho) s^{-\rho} ,
 \label{eqn:generalTauberian}
\end{align}
%
has to be used, which is derived in Sec. \ref{sec:tauberian}. Here $k_{\max}$ is the whole part of $-\rho$, and $I^{f}_k$ is the moment integral
%
\begin{align}
I^{f}_k = \int_0^\infty t^k f(t) dt.
\end{align}



\section{Method for calculating the PDF}

% great previous work by magdziarz
{\color{blue} \
So far there exist no analytic solution for the \gls{PDF} of the original L\'evy walk for general values of $\gamma$ and $\nu$, which makes finding it for the generalized model a difficult task.
} 
However there is a remarkable result by Magdziarz who found closed expressions for the \gls{PDF} in any dimension for the special case $\nu=1$ (i.e. the velocity model) \cite{magdziarz2015, magdziarz2016}. It is therefore tempting to see if his method might be generalized and applied to our case. Unfortunately this turned out to be impossible, as the technique for performing the inverse transform relied heavily on the scaling of the transformed \gls{PDF}, $\gls{pdf}(\ve{k}|s) \propto f\left( \frac{k}{s} \right)$, which is not preserved when $\nu$ deviates from 1. In this case the function scales as $\gls{pdf}(\ve{k}|s) \propto f\left(\frac{k}{s^{\nu}} \right)$ which makes the method unworkable for arbitrary $\nu$.

Instead an asymptotic approach is taken, where the starting point for the calculation is the general expression for the transformed \gls{PDF} found in  Eq. (\ref{eqn:pdfFourierLaplaceII}):
%
\begin{align}
\gls{pdf}(\ve{k}|s) = \frac{ \gls{rest}(\ve{k}|s)}{1 - \gls{psi}(\ve{k},s)}  .
\end{align}
%
Here an expansion is again performed for the one dimensional PDF, analogously to the calculation of the $\gls{msd}$. \\
For the inverse Laplace transform analytical results are supplemented with the use of numerical inverse transforms. These can be performed very efficiently through the use of the algorithm proposed by Talbot \cite{talbot1979}, which has been slightly improved and implemented in Mathematica in \cite{abate2004}.


\section{Numerical simulation of the model}

% why use direct simulation
Numerical simulations supplement and support analytical computations by giving insight into the qualitative structure of the process, sharpening the understanding of the model and giving a method of testing the results. Furthermore numerical methods allow the investigation of regimes where analytical computations fail.
%{\color{blue}
%In general there are two possible approaches for the simulation of a L\'evy walk model: On the one hand a direct simulation of the process, where I randomly generate step durations and directions for a large ensemble of walkers and record their positions; or on the other hand a description via a suitable Langevin equation, which has been shown to be equivalent to a L\'evy walk. \todo{is it?}
%where  I decided to go with the former approach as it keeps closer to the model and avoids potential numerical instabilities that can appear during the integration of differential equation. It is also not entirely clear how the generalization of the L\'evy walk studied in this paper could be reflected in a Langevin equation. 
%}

The simulation implemented for this thesis creates an ensemble of L\'evy walkers, each of which performing steps whose length and direction is determined by a pseudorandom number generator. Information about the process is then extracted by averaging over the ensemble. \\
Such an approach is very robust compared to the integration of stochastical differential equations, as it only involves addition and multiplication and is therefore very unlikely to run into numerical instabilities. 

The two main quantities that we are interested in for this thesis are the \gls{msd} and the \gls{PDF} of the generalized L\'evy walk: The former can be found by computing the position of the walkers at preset measurement times and taking the ensemble averages. For the latter the distance from the origin is split into discrete bins that track how many particles are in their respective interval. The \gls{PDF} can then be approximated by plotting the bins in a histogram. The simulation was implemented in one dimension similarly to the analytical computation, as this captures most of the behavior in an isotropic walk. 

When performing the simulation duration of the walk and the size of the ensemble have the biggest impact on computation times, where the second factor is of special importance for processes with power law distributions such as L\'evy walks, because here the walk is often dominated by rare events which are only captured with sufficiently large ensembles. \\
To address this issue I use the independence of the different walkers to parallelize the computation and perform it on the available graphics cards (GPUs) using NVIDIA's C++ extension CUDA. The university computers are equipped with Quadro K4000 GPUs, that have 768 cores each. This is a far than greater number of cores than available on processor (CPU), which is usually less than ten, and thus allows for far greater parallelization, resulting in a considerable speedup of the simulation. \todo{quantify this?} \\
Possible hurdles to this approach are the latency in the data transfer between working memory and GPU, which can slow down performance, and the limited memory on the GPU (3GB). However by limiting the walker positions I save to selected measurement times and reducing communication between GPU and CPU to a minimum it was possible to simulate large ensembles of $10^9$ particle in a few hours. 

Another aspect that should be addressed is the generation of pseudo random numbers for the creation of the steps for the simulation. As these numbers are not truly random, i.e. not completely uncorrelated, they can, depending on the quality of the number generator, leave statistical artifacts that falsify the simulation results. To minimize this risk I use the cuRAND library, which implements a version of the Xorshift algorithm \cite{marsaglia2003xorshift}. The documentation guarantees a period greater than $2^{190}$ for each independently seeded sequence of random numbers (i.e. each simulation), and each thread has an offset of $2^{67}$ in this sequence. At roughly $10^{9}$ threads that each simulate a random walker with a step number lower than $10^{7}$ I am more than ten orders of magnitude away from reaching the period of the random number sequence, which leaves little risk that statistical artifacts influenced the results.
